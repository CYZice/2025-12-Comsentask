## 小目标检测优化研究

### 1. 任务背景与难点
无人机视角（VisDrone）下的目标检测面临巨大挑战。物体（如车辆、行人）在画面中占比极低（往往小于 30x30 像素），在经过 YOLO 标准的 32 倍下采样后，特征图上仅剩不到 1 个像素，导致特征丢失严重。

本实验旨在对比两种不同优化策略在小目标检测上的有效性：
1.  **数据增强法**：增大输入分辨率（Input Resolution Scaling）。
2.  **架构改进法**：引入 P2 高分辨率检测头（P2 High-Res Head）。

### 2. 实验设置

*   **数据集**：VisDrone-2019 (部分子集)
*   **基础模型**：YOLOv8n (Baseline)
*   **训练轮数**：30 Epochs。Method B由于无预训练模型，训练了130Epochs

| 实验组别 | 简述 | 原理 |
| :--- | :--- | :--- |
| **Baseline** | YOLOv8n, imgsz=640 | 官方基准模型，不做修改。 |
| **Method A** | YOLOv8n, **imgsz=1280** | 通过增大输入图像，强行保留小物体像素信息，使其在深层特征图中依然可见。 |
| **Method B** | **YOLOv8-P2**, imgsz=640 | 修改 YAML 结构，增加 4倍下采样 (P2) 的输出层                 |

### 结果分析 (Results & Analysis)

| 模型配置 | mAP@50 | Recall (召回率) |
| :--- | :--- | :--- |
| Baseline (640) | 0.22461 | 0.24828 |
| **Method A (1280)** | 0.28157 | 0.30189 |
| **Method B (P2-640)** | 0.23417 | 0.20564 |

#### 对比分析

1.  增大分辨率是最直接的手段。30x30 的物体在 1280 输入下变成了 60x60，对于这种尺寸的物体，YOLO 原有的 P3/P4 层也能轻松识别。且该方法完整保留了预训练权重 ，收敛极快，但缺点是消耗显存。

2.   修改网络结构后，由于没有预训练的相关参数，相当于从头训练，所以效果比其他较差

-   由于修改了 Head 结构并新增了 P2 通路，这部分参数是从零初始化 的。相比于全参数微调的 Method A，Method B 处于欠拟合状态。在训练了130Epoch之后，召回率和mAP50分数接近Baseline,并仍然快速上升

### 5. 实验总结

本实验验证了解决小目标检测的两个核心方向。
*   **增大分辨率**是提升精度的“捷径”，适合硬件资源充足的场景。
*   **修改 P2 结构**是提升效能的“正道”，它通过架构优化解决了特征消失的根本问题。
在实际工程中，使用 P2 结构配合适当的分辨率提升，并在训练初期加入 Warmup 策略以解决新层级收敛慢的问题。